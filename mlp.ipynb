{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepping data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize as minimize\n",
    "from itertools import islice\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ktEAeLomt37c"
   },
   "outputs": [],
   "source": [
    "# splitting data in train test and val set\n",
    "def data_split(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)  \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)\n",
    "    return X_train, X_test, X_val, y_train, y_test, y_val\n",
    "\n",
    "data = pd.read_excel(r'C:\\Users\\RE-Giorgio\\Downloads\\dataPoints.xlsx')\n",
    "X = np.array(data.iloc[:,:2])\n",
    "y = np.array(data.iloc[:, 2])\n",
    "X_train, X_test, X_val, y_train, y_test, y_val = data_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network parent class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShallowNeuralNetwork:\n",
    "    \n",
    "    def __init__(self, X, y, N, sigma):\n",
    "\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.N = N\n",
    "        self.bias = np.random.normal(self.N)\n",
    "        self.weights1 = np.random.normal(0,1,(self.X.shape[1], self.N))\n",
    "        self.weights2 = np.random.normal(0,1,(self.N, 1))\n",
    "        self.output = np.zeros(y.shape[0])\n",
    "        self.rho = np.random.normal(10e-4,10e-5,1)\n",
    "        self.sigma = sigma\n",
    "    \n",
    "    # needed to apply the norm on the parameters' vectors all togheter for the regularization\n",
    "    def concatenate(self,l):\n",
    "        \n",
    "        l = [np.array(array).reshape(-1,1) for array in l]\n",
    "        return np.concatenate(l)\n",
    "    \n",
    "    # needed to divide the concatenated vectors for the forward propagation\n",
    "    def separate(self, l):\n",
    "    \n",
    "        seclist = [self.X.shape[1]*self.N, self.N, self.N]\n",
    "        return [list(islice(iter(l), 0, i)) for i in seclist]\n",
    "    \n",
    "    def loss(self,params, fixed_params):\n",
    "        \n",
    "        weights1, weights2, bias = self.separate(params)\n",
    "        y, rho, sigma = fixed_params\n",
    "        return 0.5 * np.mean(np.square((self.act_fun(self.predict(self.X)) - y))) +\\\n",
    "            rho*np.square(np.linalg.norm(self.concatenate([weights1, weights2, bias])))\n",
    "    \n",
    "    def mse(self, x, y):\n",
    "        return 0.5*np.mean(np.square(self.predict(x) - y)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP child class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F9ffLn4Tt37m"
   },
   "outputs": [],
   "source": [
    "class Mlp(ShallowNeuralNetwork):\n",
    "    \n",
    "    def act_fun(self,x):\n",
    "        return (1-np.exp(-2*x*self.sigma))/(1+np.exp(-2*x*self.sigma))\n",
    "\n",
    "    def predict(self, x):\n",
    "        \n",
    "        hidden_layer = self.act_fun(np.dot(x, self.weights1)) + self.bias\n",
    "        self.output = np.dot(hidden_layer, self.weights2)\n",
    "        return self.output\n",
    "                          \n",
    "    def optimize(self):\n",
    "        \n",
    "        function_args = np.array([self.y, self.rho, self.sigma])\n",
    "        inits = self.concatenate([self.weights1, self.weights2, self.bias])\n",
    "        \n",
    "        start = time.time()\n",
    "        result =  minimize(self.loss, x0 = inits, method='CG', args = function_args)\n",
    "        time_elapsed = time.time() - start\n",
    "        print(result)\n",
    "        \n",
    "        self.weights1 = np.array(self.separate(result.x)[0]).reshape((self.X.shape[1], self.N))\n",
    "        self.weights2 = np.array(self.separate(result.x)[1]).reshape((self.N, 1))\n",
    "        self.bias = np.array(self.separate(result.x)[2]).reshape(self.N)\n",
    "        \n",
    "        func_eval = result.nfev\n",
    "        grad_eval = result.njev\n",
    "        iterations = result.nit\n",
    "        opt_fun = result.fun\n",
    "        return func_eval, grad_eval, iterations, opt_fun, time_elapsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## first run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5flLC-Vkt37p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fun: 0.6953942762363102\n",
      "     jac: array([ 2.23517418e-08, -2.98023224e-08,  1.26659870e-07, -5.96046448e-08,\n",
      "        0.00000000e+00, -2.23517418e-08,  2.98023224e-08, -1.49011612e-08,\n",
      "        1.49011612e-08, -4.47034836e-08,  7.45058060e-09, -2.98023224e-08,\n",
      "        7.45058060e-09,  2.98023224e-08,  1.49011612e-08, -2.23517418e-08,\n",
      "        7.45058060e-09,  2.23517418e-08,  2.23517418e-08, -1.49011612e-08,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00])\n",
      " message: 'Optimization terminated successfully.'\n",
      "    nfev: 858\n",
      "     nit: 5\n",
      "    njev: 26\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([ 3.33708159e-06, -5.81336332e-06,  1.93344472e-05, -9.95628536e-06,\n",
      "       -6.20114647e-07, -4.29822550e-06,  4.59878652e-06, -3.13316252e-06,\n",
      "        1.68317594e-06, -7.14026061e-06,  1.29653849e-06, -1.51407286e-05,\n",
      "        1.01954028e-06,  1.17617076e-05,  5.24241017e-06, -1.16164149e-05,\n",
      "        2.24258660e-06,  8.09626643e-06,  8.16778887e-06, -8.84234722e-06,\n",
      "       -8.74167137e-01, -2.97707957e-01,  1.27493857e+00, -8.20430898e-01,\n",
      "        2.80859052e+00,  1.24567482e+00, -1.46055802e+00, -1.37488909e-01,\n",
      "        4.83011931e-01,  4.38962929e-01,  8.71107876e+00])\n",
      "Training Error : 1.3795951874319023\n"
     ]
    }
   ],
   "source": [
    "nn = Mlp(X_train, y_train, 10, 1)\n",
    "func_eval, grad_eval, iterations, opt_fun, time_elapsed = nn.optimize()\n",
    "print(\"Training Error :\", nn.mse(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2219066124006976"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.predict(X_test)\n",
    "nn.mse(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of mlp.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
