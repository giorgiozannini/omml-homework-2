{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepping data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ktEAeLomt37c"
   },
   "outputs": [],
   "source": [
    "# file imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize as minimize\n",
    "from itertools import islice\n",
    "\n",
    "# splitting data in train test and val set\n",
    "def data_split(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)  \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)\n",
    "    return X_train, X_test, X_val, y_train, y_test, y_val\n",
    "\n",
    "data = pd.read_excel(r'C:\\Users\\RE-Giorgio\\Downloads\\dataPoints.xlsx')\n",
    "X = np.array(data.iloc[:,:2])\n",
    "y = np.array(data.iloc[:, 2])\n",
    "X_train, X_test, X_val, y_train, y_test, y_val = data_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network parent class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self, X, y, N, sigma):\n",
    "\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.N = N\n",
    "        self.bias = np.zeros(self.N)\n",
    "        self.weights1 = np.random.normal(0,1,(self.X.shape[1], self.N))\n",
    "        self.weights2 = np.random.normal(0,1,(self.N, 1))\n",
    "        self.output = np.zeros(y.shape[0])\n",
    "        self.rho = np.random.normal(10e-4,10e-5,1)\n",
    "        self.sigma = sigma\n",
    "    \n",
    "    # needed to apply the norm on the parameters' vectors all togheter for the regularization\n",
    "    def concatenate(self,l):\n",
    "        l = [np.array(array).reshape(-1,1) for array in l]\n",
    "        return np.concatenate(l)\n",
    "    \n",
    "\n",
    "    def loss(self,params, fixed_params):\n",
    "        \n",
    "        # the next 2 lines are two divide the concatenated vectors for the forward propagation\n",
    "        seclist = [self.X.shape[1]*self.N, self.N, self.N]\n",
    "        weights1, weights2, bias = [list(islice(iter(params), 0, i)) for i in seclist]\n",
    "        y, rho, sigma = fixed_params\n",
    "        return 0.5 * np.mean(np.square((self.act_fun(self.forward_propagation()) - y))) +\\\n",
    "            rho*np.square(np.linalg.norm(self.concatenate([weights1, weights2, bias])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP child class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F9ffLn4Tt37m"
   },
   "outputs": [],
   "source": [
    "class Mlp(NeuralNetwork):\n",
    "    \n",
    "    def act_fun(self,x):\n",
    "        return (1-np.exp(-2*x*self.sigma))/(1+np.exp(-2*x*self.sigma))\n",
    "\n",
    "    def forward_propagation(self):\n",
    "        \n",
    "        self.hidden_layer = self.act_fun(np.dot(self.X, self.weights1))\n",
    "        self.output = np.dot(self.hidden_layer, self.weights2)\n",
    "        return self.output\n",
    "                          \n",
    "    def optimization(self):\n",
    "        function_args = np.array([self.y, self.rho, self.sigma])\n",
    "        inits = self.concatenate([self.weights1, self.weights2, self.bias])\n",
    "        return minimize(self.loss, x0 = inits, method='CG', args = function_args)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## first run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5flLC-Vkt37p"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 1.674591715823805\n",
       "     jac: array([-1.68383121e-06,  7.00354576e-07,  1.19209290e-07, -2.53319740e-07,\n",
       "        1.11758709e-06, -4.17232513e-07,  2.57790089e-06,  5.06639481e-07,\n",
       "        9.38773155e-07, -9.83476639e-07, -1.34110451e-07, -5.81145287e-07,\n",
       "        4.61935997e-07, -5.96046448e-08,  4.91738319e-07,  2.23517418e-07,\n",
       "        2.23517418e-07,  3.87430191e-07,  2.53319740e-07,  5.96046448e-08,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00])\n",
       " message: 'Optimization terminated successfully.'\n",
       "    nfev: 1092\n",
       "     nit: 5\n",
       "    njev: 26\n",
       "  status: 0\n",
       " success: True\n",
       "       x: array([-2.55695756e-04,  1.08601523e-04,  1.86828097e-05, -3.86390501e-05,\n",
       "        1.72276371e-04, -6.29238280e-05,  3.95322508e-04,  7.84418761e-05,\n",
       "        1.43401030e-04, -1.48952769e-04, -5.94500398e-05, -2.66887052e-04,\n",
       "        2.12127021e-04, -2.73392882e-05,  2.29855421e-04,  1.00915388e-04,\n",
       "        1.04803479e-04,  1.80661758e-04,  1.19004544e-04,  2.72706393e-05,\n",
       "        1.32840360e+00, -9.11432831e-01,  1.33559493e+00,  5.65282968e-01,\n",
       "       -2.04015086e-01, -7.30130006e-01, -4.59536269e-01, -8.56352946e-02,\n",
       "       -2.65456088e-01, -1.92255621e-02,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = Mlp(X_train, y_train, 10, 1)\n",
    "nn.optimization()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of mlp.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
